apiVersion: v1
kind: Namespace
metadata:
  name: ray
---
apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: raycluster-latest
  # Ensure this is in the correct namespace if different from 'default'
  namespace: ray
spec:
  # The Kubernetes Service discovery requires a unique name for the head service.
  # The full service name will be: raycluster-latest-head-svc
  
  # Set the desired Ray version to match the client
  rayVersion: "2.50.0"
  
  # ====== Head Pod Configuration ======
  headGroupSpec:
    rayStartParams:
      dashboard-host: "0.0.0.0"
      # The head node will manage the GCS and Dashboard.
    template:
      spec:
        # Schedule head node on eq-01 for better performance
        nodeSelector:
          kubernetes.io/hostname: eq-01
        # Define the container for the head node
        containers:
          - name: ray-head
            # Use the lean CPU-based Ray image
            image: "rayproject/ray:2.50.0-py311"            
            ports:
              - name: gcs
                containerPort: 6379
              - name: dashboard
                containerPort: 8265
              - name: client
                containerPort: 10001
            resources:
              requests:
                cpu: "1"
                memory: "2Gi"
              limits:
                cpu: "2"
                memory: "4Gi"
  
  # ====== Worker Pod Configurations ======
  workerGroupSpecs:
    
    # --- Worker Group 1: GPU worker ---
    - groupName: gpu-worker-group
      replicas: 1
      minReplicas: 1
      maxReplicas: 5
      rayStartParams: {}
      template:
        spec:
          # Ensure scheduling only on GPU nodes
          nodeSelector:
            nvidia.com/gpu.present: "true"
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          containers:
            - name: ray-gpu-worker
              # Use the lean GPU-based Ray image
              image: "rayproject/ray:2.50.0-py311-gpu"                  
              lifecycle:
                preStop:
                  exec:
                    command: ["/bin/sh","-c","ray stop"]
              resources:
                requests:
                  cpu: "2"
                  memory: "4Gi"
                  nvidia.com/gpu: "1" 
                limits:
                  cpu: "4"
                  memory: "8Gi"
                  nvidia.com/gpu: "1" # Request the physical GPU resource

    # --- Worker Group 2: The CPU worker ---
    - groupName: cpu-worker-group
      replicas: 1
      minReplicas: 1
      maxReplicas: 5
      rayStartParams: {}
      template:
        spec:
          containers:
            - name: ray-cpu-worker
              # Use the lean CPU-based Ray image
              image: "rayproject/ray:2.50.0-py311"
              lifecycle:
                preStop:
                  exec:
                    command: ["/bin/sh","-c","ray stop"]
              resources:
                requests:
                  cpu: "2"
                  memory: "8Gi"
                limits:
                  cpu: "4"
                  memory: "16Gi"